{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7bd6ff76-1b39-4174-90ae-4ff3c2c1cab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# csv 파일 주소\n",
    "data_csv_url = './csv_data/emotion_data3.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "102e6b62-d637-453d-b22b-2f2c2afe92dc",
   "metadata": {},
   "source": [
    "# split train_ds, validation_ds, test_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02cf0afd-2fb5-4347-9bf2-ca244ed3f557",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dfb28857-9d70-41f1-9681-469f39384675",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Sentence</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>언니 동생으로 부르는게 맞는 일인가요..??</td>\n",
       "      <td>괴로움</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>그냥 내 느낌일뿐겠지?</td>\n",
       "      <td>괴로움</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>아직너무초기라서 그런거죠?</td>\n",
       "      <td>괴로움</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>유치원버스 사고 낫다던데</td>\n",
       "      <td>괴로움</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>근데 원래이런거맞나요</td>\n",
       "      <td>괴로움</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>남자친구가 떠날까봐요</td>\n",
       "      <td>괴로움</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>이거 했는데 허리가 아플수도 있나요? ;;</td>\n",
       "      <td>괴로움</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>내가불안해서꾸는걸까..</td>\n",
       "      <td>괴로움</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>일주일도 안 남았당...ㅠㅠ</td>\n",
       "      <td>괴로움</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>약은 최대한 안먹으려고 하는데좋은 음시있나요?0</td>\n",
       "      <td>괴로움</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>구직활동 하면서 남는시간은 뭘로 활용해야 되지..</td>\n",
       "      <td>괴로움</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>괜찮은분 같아서 괜히 조급해지네요 ㅜ</td>\n",
       "      <td>괴로움</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>제가 스타일을 바꾸면 더 어색하게만 변할것같아서 ㅠ0</td>\n",
       "      <td>괴로움</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>아내 있으면 여자 있는 술집가면 법 적으로 문제있나요?</td>\n",
       "      <td>괴로움</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>한소리들을지.... 도와주세요</td>\n",
       "      <td>괴로움</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>도와주실분 없나요..</td>\n",
       "      <td>괴로움</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>그냥 잡다한거말고학업에 관련된거 듣는게 더 좋은가요?</td>\n",
       "      <td>괴로움</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>가격은 반값....이거 질이 다른건가요??</td>\n",
       "      <td>괴로움</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>마지막에 말씀 드렸던대로 글은 이제 내릴게요의도치않게 실시간베스트글에 올라가서 남친...</td>\n",
       "      <td>괴로움</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>화장품회사다보니, 젊은 여자들이 많은거 같은데 걱정이네요..</td>\n",
       "      <td>괴로움</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0                                           Sentence test\n",
       "0            0                           언니 동생으로 부르는게 맞는 일인가요..??  괴로움\n",
       "1            1                                       그냥 내 느낌일뿐겠지?  괴로움\n",
       "2            2                                     아직너무초기라서 그런거죠?  괴로움\n",
       "3            3                                      유치원버스 사고 낫다던데  괴로움\n",
       "4            4                                        근데 원래이런거맞나요  괴로움\n",
       "5            5                                        남자친구가 떠날까봐요  괴로움\n",
       "6            6                            이거 했는데 허리가 아플수도 있나요? ;;  괴로움\n",
       "7            7                                       내가불안해서꾸는걸까..  괴로움\n",
       "8            8                                    일주일도 안 남았당...ㅠㅠ  괴로움\n",
       "9            9                         약은 최대한 안먹으려고 하는데좋은 음시있나요?0  괴로움\n",
       "10          10                        구직활동 하면서 남는시간은 뭘로 활용해야 되지..  괴로움\n",
       "11          11                               괜찮은분 같아서 괜히 조급해지네요 ㅜ  괴로움\n",
       "12          12                      제가 스타일을 바꾸면 더 어색하게만 변할것같아서 ㅠ0  괴로움\n",
       "13          13                     아내 있으면 여자 있는 술집가면 법 적으로 문제있나요?  괴로움\n",
       "14          14                                   한소리들을지.... 도와주세요  괴로움\n",
       "15          15                                        도와주실분 없나요..  괴로움\n",
       "16          16                      그냥 잡다한거말고학업에 관련된거 듣는게 더 좋은가요?  괴로움\n",
       "17          17                            가격은 반값....이거 질이 다른건가요??  괴로움\n",
       "18          18  마지막에 말씀 드렸던대로 글은 이제 내릴게요의도치않게 실시간베스트글에 올라가서 남친...  괴로움\n",
       "19          19                  화장품회사다보니, 젊은 여자들이 많은거 같은데 걱정이네요..  괴로움"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_pd = pd.read_csv(data_csv_url)\n",
    "\n",
    "data_pd.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7eb29c0d-c108-4019-8e74-69e089c5f6a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Index(['Unnamed: 0', 'Sentence', 'test'], dtype='object'), (42729, 3))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data 컬럼, 데이터 shape 조회\n",
    "data_pd.columns, data_pd.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9366a833-1519-4d96-9a8f-d2134882a254",
   "metadata": {},
   "source": [
    "## 데이터를 무작위로 섞고, 컬럼명을 변경해준다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7540a39f-b871-4859-ba94-067b60b47f0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9985</th>\n",
       "      <td>우리는 백년안애 다시돌아와 너희를 통치할것이다.</td>\n",
       "      <td>중립</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25865</th>\n",
       "      <td>어떤 정치인과 관련되어 있는지 조사해보면 나옴</td>\n",
       "      <td>중립</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11177</th>\n",
       "      <td>어디 투자함?</td>\n",
       "      <td>중립</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5238</th>\n",
       "      <td>흐앙ㅠㅠ고치는법좀요</td>\n",
       "      <td>괴로움</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26208</th>\n",
       "      <td>이렇게 된 이상 민사로는 이빠이 당겨야된다</td>\n",
       "      <td>중립</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26180</th>\n",
       "      <td>전에 애플 영업이익 비교해가며 망한다고 방송한곳도 엠비씨 아님? ㅋ</td>\n",
       "      <td>중립</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38741</th>\n",
       "      <td>잘난  남의편이라고 남편이라 살고 있는데 너무 피곤해요 남들은 다부러워하지만 뭘하나...</td>\n",
       "      <td>싫음</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32605</th>\n",
       "      <td>내일도,내일 모래두....기분좋은 하루 되세요...^^</td>\n",
       "      <td>행복</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3553</th>\n",
       "      <td>고민 되네요.....</td>\n",
       "      <td>괴로움</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22144</th>\n",
       "      <td>초코우유좋다해서먹었는데..</td>\n",
       "      <td>슬픔</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30680</th>\n",
       "      <td>솔직히 남자친구한테 말은 안하지만 고마운게참 많다..</td>\n",
       "      <td>행복</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40673</th>\n",
       "      <td>#내일\\n재택근무하는날\\n나태하지 않을 것이라 마음먹는다</td>\n",
       "      <td>설렘</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38262</th>\n",
       "      <td>아침부터 졸려요</td>\n",
       "      <td>싫음</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30161</th>\n",
       "      <td>당신같은분께서 민주주의의 양심입니다!!!!</td>\n",
       "      <td>행복</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34505</th>\n",
       "      <td>#일상 점심먹고 너무 졸려서 잠깐 눈붙인다는게 한시간...ㅋㅋㅋ낮잠 조하 방학 조하..</td>\n",
       "      <td>중립</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5789</th>\n",
       "      <td>공부를 잘 하셨데요</td>\n",
       "      <td>중립</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30025</th>\n",
       "      <td>김재현오빠는 짱먹구......</td>\n",
       "      <td>행복</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5512</th>\n",
       "      <td>정말 대단하다...</td>\n",
       "      <td>중립</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1509</th>\n",
       "      <td>어느날 갑자기 성자들이나 된 마냥 수십년을 넘게 행해지고 있던걸 자기만 모르다 이제...</td>\n",
       "      <td>괴로움</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38385</th>\n",
       "      <td>오늘도 화이팅!!!\\n출근길 긍정에너지를 끌어올리기 위한 \\n노래듣기ㅋㅋㅋ#쏟아라#...</td>\n",
       "      <td>행복</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                sentence label\n",
       "9985                          우리는 백년안애 다시돌아와 너희를 통치할것이다.    중립\n",
       "25865                          어떤 정치인과 관련되어 있는지 조사해보면 나옴    중립\n",
       "11177                                            어디 투자함?    중립\n",
       "5238                                          흐앙ㅠㅠ고치는법좀요   괴로움\n",
       "26208                            이렇게 된 이상 민사로는 이빠이 당겨야된다    중립\n",
       "26180              전에 애플 영업이익 비교해가며 망한다고 방송한곳도 엠비씨 아님? ㅋ    중립\n",
       "38741  잘난  남의편이라고 남편이라 살고 있는데 너무 피곤해요 남들은 다부러워하지만 뭘하나...    싫음\n",
       "32605                     내일도,내일 모래두....기분좋은 하루 되세요...^^    행복\n",
       "3553                                         고민 되네요.....   괴로움\n",
       "22144                                     초코우유좋다해서먹었는데..    슬픔\n",
       "30680                      솔직히 남자친구한테 말은 안하지만 고마운게참 많다..    행복\n",
       "40673                    #내일\\n재택근무하는날\\n나태하지 않을 것이라 마음먹는다    설렘\n",
       "38262                                           아침부터 졸려요    싫음\n",
       "30161                            당신같은분께서 민주주의의 양심입니다!!!!    행복\n",
       "34505   #일상 점심먹고 너무 졸려서 잠깐 눈붙인다는게 한시간...ㅋㅋㅋ낮잠 조하 방학 조하..    중립\n",
       "5789                                          공부를 잘 하셨데요    중립\n",
       "30025                                   김재현오빠는 짱먹구......    행복\n",
       "5512                                          정말 대단하다...    중립\n",
       "1509   어느날 갑자기 성자들이나 된 마냥 수십년을 넘게 행해지고 있던걸 자기만 모르다 이제...   괴로움\n",
       "38385  오늘도 화이팅!!!\\n출근길 긍정에너지를 끌어올리기 위한 \\n노래듣기ㅋㅋㅋ#쏟아라#...    행복"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 컬럼 명 변경\n",
    "data_pd = data_pd.rename(columns={'Sentence': 'sentence', 'test': 'label'})\n",
    "\n",
    "# Unnamed 컬럼 제거\n",
    "data_pd = data_pd.drop('Unnamed: 0', axis=1)\n",
    "\n",
    "# 데이터를 무작위로 섞어준다\n",
    "shuffled_data = data_pd.sample(frac=1)\n",
    "shuffled_data.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe77a712-5c2c-408b-9155-e1d726d2603b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 커스텀 Dataset을 이용해서 PyTorch 학습, 검증, 테스트 데이터셋 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4697e2eb-7ab8-4931-b6f9-1912488b33dc",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 학습 데이터셋 클래스 분포 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9cdb9966-4709-48be-b184-f1393fdf559a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjQAAAGxCAYAAAB1Hiz1AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA120lEQVR4nO3deXTU1f3/8ddkYQKBJCxCWUIAWYIECPuismgJUWRVMFBBW9kpS7FCU9QQjCKbgoo/qBaNWgUEKy07iIhA0VIFihBACJVNZM2wTrb7+8PDfBkngQQzM/mE5+OcOcfPvXc+n/dccpKX97OMzRhjBAAAYGEB/i4AAADglyLQAAAAyyPQAAAAyyPQAAAAyyPQAAAAyyPQAAAAyyPQAAAAyyPQAAAAyyPQAAAAyyPQAAAAyyPQACiUF154QTabzeMVFxfn79IA3MaC/F0AAGvJysrS/fffryVLlri12+12P1UEAAQaALcgKChIERER/i4DAFw45QSgyBw9elR33HGH/ve//6l9+/YKDQ3VqlWrJEkXLlzQyJEjValSJYWGhuqhhx7SoUOH3N6fmZmpCRMm6Fe/+pVCQ0N13333aefOnYqNjdW2bdtc46Kjo922rylbtqw2b97s1vbyyy+rdu3aCgkJUYsWLbRu3Tq3/o4dO+rdd9/VkCFDVKlSJYWHhys+Pl6HDx/22P+3336r3r17q3z58ipVqpRq166tnTt3qlevXnruuefcxp4+fVphYWE6evRooeYQwK0h0AAoMtnZ2crKytKYMWP07LPP6rvvvtO9994rY4x69eqlvXv3atWqVdqxY4eioqL061//WpmZma73T5w4UQsWLFBqaqoOHTqkIUOGqHv37jpz5oyuXr3qGnf16lW37euPn52d7dqeMmWKZs+erblz52r//v0aPHiw+vTpo2+//dY1xmazKTExUVevXtWGDRu0Y8cOVa1aVT169JAxxjXuq6++Urt27VS/fn1t3bpVR48e1cKFCxUVFaVHH31U7733nlstixYtUtOmTVWjRo0imVsAN2EAoBCSkpJM165d8+xLT083ksy0adPc2pctW2YqV65sLl686NYeExNj3nnnHWOMMQ6Hw5QtW9Z8/PHHbmNef/11I8l89tlnrraoqCi37Wvsdrur/ccffzSlSpUyX331lduY3//+9+aJJ55wbXfs2NE0adLE5ObmutouXrxoypUr53pvbm6uiYmJMRMmTMjzc1+6dMmULVvWbNu2zdXWvn17M3/+/DzHAyh6rNAAKLRPP/1UERERbq9Zs2a5+rt37+42fsWKFerVq5dCQ0Pd2jt37uw6dbRz507l5OTooYcechszaNCgW6px/fr1qlWrllq1apXvMa/59a9/LZvN5toODQ3VnXfeqfT0dEnSrl27tHv3bk2cODHPY5UpU0a9e/fW4sWLJUmHDx/Wf/7zH/Xt2/eWagdQeFwUDKDQ2rdvr9TUVLe2O+64Q6dOnZIk1axZ063v8OHD2rRpkxYtWuTWfvXqVXXt2lWSdPz4cVWpUkXBwcFuY8qVK6c77rij0DUePnxYhw4d8rh4OTs7W4GBgR61/1x4eLguX74sSUpLS9OvfvUrVahQId/j/eY3v9HQoUM1c+ZMffDBB3rwwQdVvnz5QtcN4NYQaAAUWunSpVWrVi2P9muB5ucrMZL05JNP6o9//KNHe7ly5ST9tMpxLUD8XF7Xy/zctet3rte0aVOP28sleYSmgsjJyblh/7XrgbZt26YPPvhAU6ZMKfQxANw6Ag0Ar6tevbrOnj2bZwi6pmbNmjp16pQuXLjgCjmSdO7cOV24cMFtbOnSpT3a0tPTlZub63bMEydO3PCYBRUdHa1Tp07p6NGj+V7kGxgYqISEBD377LM6fvy4unXr9ouPC6DguIYGgNd17txZy5Yt0w8//JDvmLvuukuVKlXShx9+6Nb+/vvve4yNjIzUzp073dp+fpdRx44ddeLECf3jH//4BZX/pEmTJmrQoMFNV10ee+wxffrpp+rbty8PGgR8jEADwOv69eunOnXqqHPnzvrss8/0448/avfu3Xr++eddt20HBQVp0qRJSkxM1PLly3Xy5EktWbJEr7zyise1KAkJCXr11Ve1adMmXblyRe+9954++eQTRUVFucZERUVp8ODBGjRokFJTU3Xy5EkdPHhQb731lnbt2lWo+m02m+bOnat33nlHQ4YM0f79+3X69Glt375d58+fd41r0aKFypcvr8cee+zWJwvALeGUE4BCCQkJyXf1ISgoSEFBnr9W7Ha7NmzYoMTERPXv319nz55VpUqVdN9997ldoDt27FhlZ2drxIgROn36tFq0aKHFixfrkUcecdvfE088oe+//14DBw7U6dOn1aZNGy1dulQ9evRwO/4bb7yhmjVr6vnnn9eQIUNUrlw5NW/eXJ07d75pzSEhIQoJCXFt33///frss8/07LPPqnnz5rp69aoqVaqkFStWqEWLFpKk7du3Kzw8XPfcc08BZxNAUbEZc92TowCgGKpVq5beeecdderUyd+l5OnUqVO6fPmyhg0bpvvvv19PP/20v0sCbjuccgJQ7Nnt9jxXUYqL6dOnq0GDBipfvrzGjh3r73KA2xIrNAAAwPJYoQEAAJZHoAEAAJZHoAEAAJZXfK+yK2K5ubk6fvy4ypUr5/YldAAAoPgyxujChQuqVq2aAgLyX4e5bQLN8ePHFRkZ6e8yAADALThy5Ei+Xz0i3UaB5tp3wxw5ckRhYWF+rgYAABSEw+FQZGSk23e85eW2CTTXTjOFhYURaAAAsJibXS7CRcEAAMDyCDQAAMDyCDQAAMDyCDQAAMDyCDQAAMDyCDQAAMDybpvbtq+JSVqjAHsZf5cBAECJcfilbv4ugRUaAABgfQQaAABgeQQaAABgeT4JNLNnz1Z0dLTHKyoqShUrVtShQ4cKtb8uXbpo586dXqoWAABYjU8uCh43bpzGjRvn1nbmzBmNHj1a2dnZql27tqt92bJlmjhxosfYL774QtHR0ZKkrKwsZWVleb1uAABgDT4/5XTy5En9+c9/VsOGDdWiRQstWrTI7QunevbsqbS0NLdXmzZt9MMPP/i6VAAAYBFeX6ExxigtLU1btmzRkiVLdOjQIT300ENq06aNFixYoP3796tDhw7q2LGjatSooU2bNmn06NFyOp2ufZw9e1ZVq1b1dqkAAMCivB5o5s2bp1WrVunuu+/WlClT1Lp1a1ef0+nU1q1btXnzZgUEBKh///7697//re7duyslJeUXHdfpdLqFIofD8Yv2BwAAii+vB5oRI0ZoxIgRefbZ7XZ17txZnTt3dmvPzc1Vdna2nE6nMjIydPz4caWnp+vkyZP6/e9/X6DjTp06VcnJyb+4fgAAUPx5NdDMmDFDqampHu179uzRXXfd5dHer18/3XfffRozZozWrl2rMmXKqEyZMqpYsaIiIyNVv379Ah87MTFR48ePd207HA5FRkbe2gcBAADFms0YY3x90JCQEF29evWW33/o0CFFRkYqODi4wO9xOBwKDw9X5LjFfPUBAABFyJtffXDt73dGRobCwsLyHeezu5wyMjK0cOFCJSUlKTs7W0lJSVq0aFG+17aMGDFCaWlpefbNmDGj0M+uAQAAJZdPAs3q1atVv359LVmyRCEhIZozZ47sdrsWLVqkevXqae3atR7v2bt3r+Lj4/N8IF9qaqouXLjgi9IBAIAF+OTBelOmTNGbb76pHj16ePR98sknSkpKUlxcnEffkiVL1LJlS4/2Tp06eaNMAABgUT5ZoWnTpo0+/PBDfffdd27t+/fv14cffqhWrVrl+b78Lu/Jzc0t8hoBAIB1+WSFZsaMGZo7d64GDhyoo0ePutrr1Kmj/v37a+jQoR7viYqK0sMPP5znBUDHjx9X5cqVvVozAACwDr/c5eQP3OUEAIB3FIe7nHyyQlOc7E7uesMJAQAA1uPzL6cEAAAoagQaAABgeQQaAABgeQQaAABgeQQaAABgeQQaAABgeQQaAABgeQQaAABgeQQaAABgeQQaAABgeQQaAABgeQQaAABgeQQaAABgeQQaAABgeQQaAABgeQQaAABgeQQaAABgeQQaAABgeUH+LsDXYpLWKMBext9lALCYwy9183cJAG6AFRoAAGB5BBoAAGB5Pg80xhhfHxIAAJRwPg801atX15UrVzzaO3TooD179ri1LV68WA888IBq166t2rVrq27duurTp4/WrVvnq3IBAIAF+PSi4CtXrig7O1ulS5f26MvMzFRmZqZrOyUlRStXrtScOXPUsmVL2Ww25ebm6quvvtLYsWOVlpam0aNH+7J8AABQTPl0heaTTz7RpUuXdPLkyZuO/cc//qHp06erVatWstlskqSAgAC1bdtWL730khYuXOjtcgEAgEX4LNBcvHhRKSkp6t27twYPHqzc3Nwbju/Ro4cSExO1Y8cOV5sxRtu3b9ef//xn9e3b18sVAwAAq/DJKafLly/r0UcfVc+ePfXCCy9oxIgR6tWrlxYsWKBKlSrl+Z5nnnlGderU0R//+EcdOnRIgYGBCggIUMOGDZWUlKT4+PgbHtPpdMrpdLq2HQ5HkX4mAABQfHg90GRkZOiee+5R37599dxzz0mS5s2bp9dee03x8fHavn17vu8dMGCABgwYcEvHnTp1qpKTk2/pvQAAwFpsxgf3Ue/fv1/169fPs8/pdMoYo9WrV+v+++/X//t//08LFiwo8L4TEhI0efLkPPf78xWayMhIRY5bzJOCARQaTwoG/MPhcCg8PFwZGRkKCwvLd5xPAo3006rM66+/LkkKCgrS008/rQcffFD9+vWTMUY2m00fffSRIiIivHL8axNCoAFwKwg0gH8Uu0BzvVWrVulvf/ubGjZs6PagvaCgIP3pT3+SJM2fP1+vvvqqcnJyPN4fGBiokSNHatSoUQU+JoEGwC9BoAH8o6CBxm9fTpmbm6vTp097BJpr1q9frxdffFE9e/b0eO+yZcv0zjvvFCrQAACAkstngeatt95SSkqKKlWqpMDAQD311FOKjo7WH/7wB128eFHlypXTnDlzXOONMbLb7Xnuy2638xUKAADAxWfPoTl27JgmTpyobdu2acOGDWrXrp1mzpypsWPH6ssvv9TgwYM1Y8YM13ibzZZvaLl2zQ0AAIDkwxWau+++W1OnTtWiRYsUEhKimjVrauTIkRo/frxeeOEFBQUFafbs2a7xd955p4YMGZLnRcLnz5/X448/7qvSAQBAMeeXi4L9gYuCAfwSXBQM+EexvyjYX3Ynd73hhAAAAOvx6ZdTAgAAeAOBBgAAWB6BBgAAWB6BBgAAWB6BBgAAWB6BBgAAWB6BBgAAWB6BBgAAWB6BBgAAWB6BBgAAWB6BBgAAWB6BBgAAWB6BBgAAWB6BBgAAWB6BBgAAWB6BBgAAWB6BBgAAWB6BBgAAWF6QvwvwtZikNQqwl/F3GQAK4fBL3fxdAoBijhUaAABgeQQaAABgeQQaAABgeT4LNBMmTFDdunVVt25djRs3ztUeFRUlSfrqq6/Ur18/V/vYsWP13nvv5bmvv//97xo2bJhX6wUAANbhs4uCp0+frunTp3u0X7p0SZKUmZmpzMxMV3tOTo5ycnLy3NeN+gAAwO3H64Hm1KlTuu+++2SMcWsPDAzU5s2bb/jeZ555RjNnzvRodzgciouLK9I6AQCAdXk90Nxxxx3673//q0uXLmnbtm2SpLZt2yo0NPSm701JSdETTzzh0b5kyRKtXr26qEsFAAAW5ZNTTgcPHlS3bt3UqVMnBQYGasyYMVq6dKmio6MlSTExMbp8+bKaNGniek+dOnU0adKkPFdozp8/r+HDh9/wmE6nU06n07XtcDiK6NMAAIDixmZ+fi7ICyZOnKjo6Gj99re/lSQtXbpUGzZs0Ny5c1WpUiWdPn1amzdv1syZM/XJJ5/kuY+yZcvq4sWLBT7m5MmTlZyc7NEeOW4xD9YDLIYH6wG3L4fDofDwcGVkZCgsLCzfcT65y6l27dr617/+pZycHOXm5upf//qX6tSp49VjJiYmKiMjw/U6cuSIV48HAAD8xyennIYMGaKkpCS1adNGknT//fdr7NixkqShQ4e6jZ02bZrefvttj33UqFHDdYrqegkJCZo8ebJHu91ul91uL4LqAQBAceeTU04FceHCBaWnp7tdR1OUri1ZccoJsB5OOQG3r4KecvLpl1Pm5ORo7ty5Wrp0qS5fvqycnBwFBAQoIiJCvXv3drvQt23btjp//nye+7l48aIGDRqkF1980UeVAwCA4syngWbcuHHKzc3VP//5T7eUderUKU2cOFETJ0503dV07RbvvKxevVrz58/3er0AAMAafPpdTjabTaVKlVJAgPthg4KCVKpUKQUGBhZ4X8XkTBkAACgGfLpC88orr2jOnDmKj49XZmamsrOzFRAQoHLlyumRRx656bNlrrHZbLLZbF6uFgAAWEWxuSi4MJxOp86ePauqVasW+D1cFAxYFxcFA7evgl4UbMlAcysKOiEAAKD4KFYP1gMAAPAmAg0AALA8Ag0AALA8Ag0AALA8Ag0AALA8Ag0AALA8Ag0AALA8Ag0AALA8Ag0AALA8Ag0AALA8Ag0AALA8Ag0AALA8Ag0AALA8Ag0AALA8Ag0AALA8Ag0AALA8Ag0AALA8Ag0AALC8IH8X4GsxSWsUYC/j7zIA5OPwS938XQIAC2KFBgAAWB6BBgAAWB6BBgAAWJ5XAk2XLl20c+fOX7yf9957T126dFGdOnVUp04d3XnnnXrggQe0ePHiIqgSAACUFIW+KPivf/2rZsyY4dZms9nUtGlTLVy4UJKUlZWlrKwsV3+fPn20Z8+ePPd35coVdezYUe+++65be1JSkrZu3ao5c+borrvucrXv3btXTz31lL799lslJycXtnwAAFACFTrQPPnkk3ryySfd2owxqlixonJzcxUQ4Lno8/HHH+e7v7S0NA0cONCj/bPPPtOzzz7rFmYkqWHDhnr22Wc1evRoAg0AAJBURKecbDabgoOD8wwzN3P9Ss71HnnkEU2YMEHr1q3TxYsXJUmXLl3S+vXrNW7cOA0ePPgX1QwAAEoOnzyHpm/fvvrmm28UEhLi0RcQEKDevXt7tI8ZM0YNGzZUamqqnnrqKV28eFFhYWFq3ry5Xn75Zd199903PKbT6ZTT6XRtOxyOX/5BAABAsXTLgWbPnj168cUX9f777+v06dOqWLFivmP37t2r1atXq27duoU6RpcuXdSlS5dbqm/q1KmckgIA4DZxy4Hm8uXLOnr0qCRp9+7datCgQb5jbTabsrOzC7TfadOm6e233/Zov3TpkkJDQz3aExISNHnyZI/2xMREjR8/3rXtcDgUGRlZoBoAAIC1FMkppzZt2mj+/Pn59j/44IPq3bu3jDGSpP3796t+/fqu/oCAAH355ZcqV66cJk6cqIkTJ3rsIyQkREeOHClwTXa7XXa7vRCfAgAAWFWRBJrSpUvr6tWr+vrrrxUVFeXRP23aNE2bNs21HRISorS0tKI4NAAAQOECzaeffupaPbl48aK+//57NWzYUDabTRUrVlS9evXcTvP8EomJiUpNTVVYWJgkqVatWoqOjpb00+mjAQMGaObMmUVyLAAAYG2FCjSdOnXS2rVrlZubq+DgYJUpU0bBwcH5js/vepjrw8n1rr8e5sCBA1qwYIHi4+M9xq1evVrz5s0rTOkAAKAEK1SgCQwMVIUKFQo8Pr/rYQAAAIqSV55DExwcfMOVm4KIiorS4MGDFRER4dGXkZGhhISEX7R/AABQctjMtVuPSjiHw6Hw8HBFjlusAHsZf5cDIB+HX+rm7xIAFCPX/n5nZGS4rqvNi0+eFFyc7E7uesMJAQAA1lMk3+UEAADgTwQaAABgeQQaAABgeQQaAABgeQQaAABgeQQaAABgeQQaAABgeQQaAABgeQQaAABgeQQaAABgeQQaAABgeQQaAABgeQQaAABgeQQaAABgeQQaAABgeQQaAABgeQQaAABgeQQaAABgeUH+LsDXYpLWKMBext9lAJZx+KVu/i4BAG6KFRoAAGB5BBoAAGB5fgk0TqfTH4cFAAAllM8DzY8//qiIiAhdvnw53zHDhg1TgwYNVLp0acXExLhepUqVUsOGDTVlyhQfVgwAAIo7n14UnJmZqSFDhqhVq1YaPXq03nrrLdlsNo9x8+fP1+HDh9WrVy/t2LHD1V6rVi198cUXqlSpkg+rBgAAxZ1PVmiys7P1j3/8Qy1atFDbtm31+eefKyQkRPHx8dq1a5cvSgAAACWY11do1q1bp8GDB+vee+/VwoUL1ahRI0nS3LlztXz5cg0ePFg5OTmaNWuWOnXq5O1yAABACWQzxhhvHiAzM1NZWVkKDQ3Nd0x6errCw8NVoUIFZWdnq2XLlsrMzJTD4VBERIRr3Llz5xQREaEaNWpozZo1Nzyu0+l0u/jY4XAoMjJSkeMW8xwaoBB4Dg0Af3I4HAoPD1dGRobCwsLyHefVFZpp06bp7bffLvD4hIQETZ482e26mVs1depUJScn/+L9AACA4s/rKzSF8cYbb2jx4sUFHt+jRw+NHz8+zz5WaICiwQoNAH8qFis0hTVy5EiNHDmySPZlt9tlt9uLZF8AAKB480mgmTBhgtauXZtn34ULF9S/f3+lpKS42ubPn69XX31VOTk5HuMDAwM1cuRIjRo1ymv1AgAAa/FJoJk+fbqmT5+eZ9+KFSv0zjvvuLWtX79eL774onr27OkxftmyZXrnnXcINAAAwMUngWby5Ml699138zz3FRAQoBEjRri1GWPyPV1kt9tVjC77AQAAxYBPAs2+ffv0xhtvKD4+vkDjbTZbvqHFGJPn04UBAMDtyyeBpkGDBho6dGi+VyeHh4dry5Ytru0777xTQ4YMcXsGzTXnz5/X448/7q1SAQCABRWr27a96dptX9y2DRQOt20D8CdL3rbtC7uTu95wQgAAgPX45MspAQAAvIlAAwAALI9AAwAALI9AAwAALI9AAwAALI9AAwAALI9AAwAALI9AAwAALI9AAwAALI9AAwAALI9AAwAALI9AAwAALI9AAwAALI9AAwAALI9AAwAALI9AAwAALI9AAwAALI9AAwAALC/I3wX4WkzSGgXYy/i7DEnS4Ze6+bsEAABKBFZoAACA5RFoAACA5fk80BhjfH1IAABQwvk80LRt21Z79+71aI+Li9POnTtv+v64uDjt27dPa9eu1ZAhQ7xRIgAAsBifB5qjR4+qSpUqHu2ZmZnKysqSJPXr10/R0dGKjo5WzZo1NWzYMI9x148HAAC3N5/e5XTs2DH9+OOPCgkJueG4xYsXu/57+/btevrpp71dGgAAsDCfrtC8/fbbstlsmj17tiTpsccec63EfPXVV3m+Jzs724cVAgAAK/LZCs3XX3+t119/XZs3b1ZCQoKaN2+u999/39XfqVMn138/8MAD2rdvn0qVKqWAgAANGjRIkydP1pIlS5Senl6g4zmdTjmdTte2w+Eoss8CAACKF58EmnXr1mnYsGFauHChWrdurTVr1qhXr17atGmTJk+erFKlSrmN37t3r7Zv365KlSq5tU+ePNkt+NzI1KlTlZycXFQfAQAAFGNeP+WUk5OjN998U8uXL3eFkXr16unLL79U9erVFRT0U6aKiYlRRESEJMlms+nKlSs6f/68Dh48qOXLl7tOUxVUYmKiMjIyXK8jR44U4acCAADFiddXaAIDA90u8r2mbNmyGjVqlGv79ddfd/33ww8/rO7du6t06dIKCwtTgwYN1KxZM0nSuHHjVLNmTZ07d05Vq1bN97h2u112u70IPwkAACiubMaHT7p7/PHH9Z///CfPvlOnTmn79u2KjIz0yrEdDofCw8MVOW4x3+UEAIBFXPv7nZGRobCwsHzH+fS27dTU1Hz77rnnHv34449ugWbo0KFatWqVQkNDPcafP39eI0eO1HPPPeeVWgEAgHX4NNAMHz5ca9euVZkyniskERERqlWrllvb/v379fe//10tW7b0GP/RRx9pxYoV3ioVAABYiE8DTVpamhYvXpxnQAEAALhVPg000dHR6tevX54rNJI0duxYt+9nioqK0iOPPKKyZct6jD137pyGDx/utVoBAIB1+DTQzJs3r1Djb3TNDQAAwDU+DTTFwe7krje8ShoAAFiPz79tGwAAoKgRaAAAgOURaAAAgOURaAAAgOURaAAAgOURaAAAgOURaAAAgOURaAAAgOURaAAAgOURaAAAgOURaAAAgOURaAAAgOURaAAAgOURaAAAgOURaAAAgOURaAAAgOURaAAAgOURaAAAgOUF+bsAX4tJWqMAexnX9uGXuvmxGgAAUBRYoQEAAJZHoAEAAJZHoAEAAJZXLAJN8+bNdezYMUnS2bNndc8997j67r77bu3bt09xcXGutjZt2igzM9PndQIAgOLJ64EmNTVVMTExbq/69etr8+bNrjGZmZnKysqSJOXm5io7O9vV53Q6lZWV5RZgLl26pNzcXG+XDgAALMLrdzk9/vjjevzxx93annzySX3//ff5vmf37t1q2bKlJGnv3r2SpP/85z+utoMHD3qpWgAAYEV+uW179+7dGjNmTL79MTEx2rZtmyS5QkyLFi20ceNGVz8AAMA1Pg80R48e1YkTJ9SkSZM8+0NDQ/W///1PsbGxkqSMjAxVq1ZN+/btc7VdvXpVdrv9hsdxOp1yOp2ubYfDUST1AwCA4sfngWbWrFkaNmyYbDZbnv2lS5fWiRMnPNrzaruRqVOnKjk5+ZZqBAAA1uLTQPPvf/9b//znP7Vr1648+6dNm6a33367wPtLSEjQ5MmT8+xLTEzU+PHjXdsOh0ORkZGFqhcAAFiDzwLNwYMHNWDAAP3tb39TmTJl8hwzceJETZw4sUiOZ7fbb3paCgAAlAw+eQ7N+vXrFRcXp7lz56pNmza+OCQAALiNeH2FZtKkSVq5cqWWLVtW4LuTEhMTlZqaqrCwMI8+h8OhAQMGaObMmUVdKgAAsCivB5qRI0dqypQpCgwMLPB7Dhw4oAULFig+Pt6jb/Xq1Zo3b15RlggAACzO64GmevXq3j4EAAC4zfnlwXo/FxwcrKCg/yslKipKgwcPVkREhMfYjIwMJSQk+LA6AABQ3NmMMcbfRfiCw+FQeHi4IsctVoD9/+6yOvxSNz9WBQAAbuTa3++MjIw8r629plis0PjS7uSuN5wQAABgPT65bRsAAMCbCDQAAMDyCDQAAMDyCDQAAMDyCDQAAMDyCDQAAMDyCDQAAMDyCDQAAMDyCDQAAMDyCDQAAMDyCDQAAMDyCDQAAMDyCDQAAMDyCDQAAMDyCDQAAMDyCDQAAMDyCDQAAMDyCDQAAMDybrtAE5O0RrX+tMLfZQAAgCJ02wUaAABQ8hBoAACA5RFoAACA5RWLQLNlyxb16dPHrW327Nn61a9+pejo6Dxf48eP91O1AACguAnyxUGeeuoprVjxfxfi5ubm6uzZs9q/f78qVKigrKwsZWZmur1n3759mjFjhgYOHOiLEgEAgIX5JNDMmjVLs2bNcm1fuHBB1atXV2hoaL7vMcbIZrP5ojwAAGBxfjnltHDhQsXHx8tut+c7xmazyel0+rAqAABgVT4PNOnp6Xruuec0ZcoUt/aNGzcqOjpaDz/8sCSpQ4cOevnll13XzAQEBLhdQzNo0KAbHsfpdMrhcLi9AABAyeSTU07XbN++Xf369dMrr7yi6Ohot75OnTpp+fLlru3+/furf//+ru2QkBClpaUV+FhTp05VcnLyLy8aAAAUez4JNKdOndL06dP10Ucf6S9/+Yvi4uLyHbt8+XJt3rzZoz07O1t/+tOfPNpbt27tcYeUJCUmJrrdCeVwOBQZGXmLnwAAABRnPgk09913n7p3765du3YpLCzMo/+uu+7S73//e0lSTEyMIiIiPMY89NBDee67WrVqebbb7fYbXqMDAABKDp8Emv/+9786ceKE4uPj87yWJSAgQL/97W8VHx+vWrVqqVatWpKkzZs367333tM333yjc+fOKSwsTM2aNdOgQYPUoUMHX5QOAAAswGcXBe/fv1+hoaHavXu3x2v69OnasGGD2/g5c+Zo7Nixeuihh7RixQrt3btXq1atUvfu3TVmzBjNmTPHV6UDAIBizmeBxhiT7ymgkJAQGWPc2j788EPNnj1b3bt31x133KGgoCBVrlxZPXv21KuvvqoPPvjAF2UDAAAL8Olt2z8PLde3//whel27dtULL7yg3bt3u95njNHOnTv1/PPPq0uXLl6vFwAAWIPPbtuuWrWq/vWvfykmJsajLyMjQ/369XNrS0pK0l//+leNHDlS6enprvb69evriSee4CsRAACAi83kt2xSwjgcDoWHhyty3GIF2Mvo8Evd/F0SAAC4iWt/vzMyMvK8U/oanz5YrzjYndz1hhMCAACsxy/f5QQAAFCUCDQAAMDyCDQAAMDyCDQAAMDyCDQAAMDyCDQAAMDyCDQAAMDyCDQAAMDyCDQAAMDyCDQAAMDyCDQAAMDyCDQAAMDyCDQAAMDyCDQAAMDyCDQAAMDyCDQAAMDyCDQAAMDyCDQAAMDyCDQAAMDyCDQAAMDyCDQAAMDyfBpoXnvtNdWtW9f1+uijj/Icd+LECdWrV881rnPnzm79Xbp00c6dO31RMgAAsIAgbx/gyJEjOnjwoCSpcePGeuutt9z6N27cKEmqV6+eqlevLkmqWrWqDhw4kO8+s7KylJWV5Z2CAQCA5Xg90OzZs0f//Oc/bzquZ8+eql69ujp27Khjx47lOaZ+/fpauXJlUZcIAAAszuuBpmvXruratatOnjypuXPnauvWrTp37pwqV66sDh06aPjw4Spfvrxr/Oeff+7tkgAAQAnjk2toHA6HWrVqperVq+uDDz7Ql19+qQULFigkJETt2rWT0+l0G//dd9+pe/fuiomJUdOmTfXoo4/q6NGjvigVAABYkE8CzenTp3XmzBn17dtXlStXVlBQkKpWraqEhASlp6crIyPDbfwjjzyiMWPGaPfu3dq5c6ceffRRDRgwoFDHdDqdcjgcbi8AAFAyef2UkyTVqVNHM2bMULt27dS0aVNVqFBBp06d0u7du/WXv/xFlStXdo01xuj48ePq1KmTqy0uLk6jRo0q1DGnTp2q5OTkovoIAACgGLMZY4yvDpaZmal9+/bp3Llzqlixoho0aKCgIM9M9cwzz2jr1q164oknlJubq7/+9a/q3r27JkyYIEnq1KmTZs6cqZYtW+Z7LKfT6XYqy+FwKDIyUhkZGQoLCyv6DwcAAIqcw+FQeHj4Tf9+e3WFZvr06VqwYIFH+8mTJ1WlShWP9oSEBE2ePFkpKSnasmWLnn/+edntds2ePVstWrQo1LHtdrvsdvst1w4AAKzDq4FmwoQJrlWV64WEhCgtLe2G77377rvVunVrGWNUtmxZrV27VgcOHFBUVJS3ygUAABblk2toCmrFihV66qmnFBAQoMDAQAUHB6t06dLatWuXatasqXr16ql27dr+LhMAABQzxSrQdOvWTd26dfN3GQAAwGL88uWUv/TaluDgYAUHBxdRNQAAwOr8skLz8+fOFNa6deuKqBIAAFAS+GWFBgAAoCgRaAAAgOURaAAAgOURaAAAgOURaAAAgOURaAAAgOURaAAAgOURaAAAgOURaAAAgOURaAAAgOURaAAAgOURaAAAgOURaAAAgOURaAAAgOURaAAAgOURaAAAgOURaAAAgOURaAAAgOURaAAAgOURaAAAgOURaAAAgOURaAAAgOURaAAAgOUVi0CzZcsW9e7d260tMzNTLVq0UGxsrGJjYzVr1iy38X369PF1mQAAoJgK8sVBUlNTNWHCBJUvX96tfdKkSRo4cKCysrKUlZXlan/33Xd19uxZDRw40G387NmzFRsbK+mnwAMAACD5KNCkp6fr6aef1h//+McCjXc6nbp69WqefVlZWQoODi7K8gAAgMX5JNAUxMaNGxUdHa1GjRpp6dKl+vjjj/XKK6+4gk1kZKRmzpypOnXqaOPGjf4tFgAAFCvFJtB06tRJy5cvlySdPn1a48aN0zfffKOKFStKklatWqXf/e53hBkAAODBJ4HGZrMpJydHkpSdna3z58/r2LFjOnjwoC5duqTIyEi38eHh4apYsaLee+89tWvXTleuXNGiRYvUqlUr15ifr+j8nNPplNPpdG07HA4vfToAAOBvPgk0bdu21fDhwzVv3jyFhISoUqVKqlatmmrVqqV7773XY3xwcLC2bNmijz76SMOHD1f9+vU1ePBgdenSxTXm+hWdvEydOlXJycle+TwAAKB48Umg6dq1q9LT0/Pt//bbb9WiRQtJ0jfffKNly5a5+mw2mxwOhxYuXKjXXntNZ86c0bhx4256zMTERI0fP9617XA4PFaCAABAyeDTa2jOnTunl156SStXrlR2draMMapYsaJ+97vfuVZTqlWrpk6dOkn6Kcx07dpVpUuXVmhoqCpVqqTy5cvr0KFDOn369A2PZbfbZbfbvf2RAABAMeCzQGOMUVxcnHr27KmtW7eqXLlykqSDBw9q9OjRSk9PV0pKiqpUqaIqVapIklavXq25c+dq3759ys7OVmBgoCpUqKAHH3xQY8aM8VXpAACgmLMZY4wvDvTDDz+oYcOGOnfunEdfWlqa+vTpoz179rjali9frkmTJumDDz5Qo0aNXO1nzpzRq6++qi+//FKrV68u8PEdDofCw8OVkZGhsLCwX/ZhAACATxT077fPvvqgSpUqqlu3rmbNmqXLly+72r///nv9+c9/1iOPPOI2Pjc3V3a73bWSc02ZMmVUrlw55ebm+qRuAABQ/PnslJPNZtOaNWv0wgsvqG3btsrOzpYklS9fXr/73e/05JNPuo3v0aOHJGnEiBE6ceKEcnJyFBgYqFKlSumBBx7QJ5984qvSAQBAMeezU07+xiknAACsp9idcgIAAPAWAg0AALA8Ag0AALA8Ag0AALA8Ag0AALA8Ag0AALA8Ag0AALA8Ag0AALA8Ag0AALA8n331gb9deyCyw+HwcyUAAKCgrv3dvtkXG9w2gebMmTOSpMjISD9XAgAACuvChQsKDw/Pt/+2CTQVKlSQ9NO3e99oQlA4DodDkZGROnLkCN+RVUSYU+9gXr2DefUO5vX/GGN04cIFVatW7YbjbptAExDw0+VC4eHht/0PhzeEhYUxr0WMOfUO5tU7mFfvYF5/UpCFCC4KBgAAlkegAQAAlnfbBBq73a6kpCTZ7XZ/l1KiMK9Fjzn1DubVO5hX72BeC89mbnYfFAAAQDF326zQAACAkotAAwAALI9AAwAALI9AAwAALO+2CDRvvvmmGjdurKZNm+qBBx7QsWPH/F1SsbNy5Urdf//9atKkiWJiYjR8+HBdvnzZ1b9371517NhRsbGxatasmT7++GO392dlZWns2LFq1KiRGjVqpNGjRyszM9NtzLJly9SsWTPFxsaqQ4cO+vbbb33y2YqDtLQ02e12JScnu9pOnDihbt26qWnTpmrcuLHmzZvn9h5jjFJSUtSoUSPFxMSof//+Ht9FtmXLFrVp00axsbFq06aNvvjiC598Hn+7cuWKkpKS1KJFCzVr1kwNGzbUhg0bXP3MbeE5HA6NGTNGTZs2VWxsrO6++26tX7/e1c/vgMJZsGCB7Ha7Dh8+7Nbui3m82c9/iWVKuNWrV5uWLVua8+fPG2OMWbRokWndurWfqyp+Pv/8c3P06FFjjDFZWVlmwIAB5qmnnjLGGHPlyhVTr149s3HjRmOMMSdOnDD169c3O3fudL3/T3/6kxk2bJjJyckxOTk5ZtSoUebpp5929e/evdvUrVvXHDt2zBhjzBdffGHq1q1rLl++7KuP6FdxcXEmPj7eTJo0ydXWrl078/777xtjjHE4HKZNmzZmxYoVrv558+aZbt26matXrxpjjJk2bZrp27evq//kyZOmZs2a5ttvvzXGGJOWlmaioqLMiRMnfPGR/CYrK8t07NjRTJ482TU3ubm5JisryzWGuS28rl27mhdffNHk5OQYY4zZvn27qVq1qjl8+DC/AwrpmWeeMfHx8aZKlSrmwIEDrnZfzePNfv5LqhIfaHr37m1Wrlzp1tauXTvzzTff+Kcgi/jmm29M48aNjTHGLFu2zPTr18+tf/78+Wbs2LHGGGNycnJM9erVzblz51z9GRkZplq1aiY7O9sYY8wf/vAH88Ybb7jto3///ubvf/+71z5DcbFkyRIzcOBAk5SU5Ao0O3fu9AjWa9asMT179nRtN2vWzOzZs8e1nZOTY2rWrGlOnz5tjDFmzpw5ZsKECW77SExMNK+88op3PkgxsWDBAtOjR498+5nbWxMcHOz6H79runXrZpYuXcrvgELIyckxc+fONdnZ2SYqKsot0PhiHgvy819SlfhTTp9++qk6dOjg1taxY0etW7fOTxVZw9mzZxUSEiJJWr9+vTp27OjWf/0c7tixQ9WqVVNERISrPywsTDVr1tTXX39doH2UVJcvX9Zzzz2nl156ya09r/m49957tWHDBhljdObMGR07dkwNGzZ09QcEBKh9+/auUyu365wuXLhQw4YNy7efub01bdu21csvv+za3rRpk7Zu3arWrVvzO6AQAgICNHLkSAUGBnr0+WIeb/bzX5KV6EBz8eJFBQUFKTQ01K09MjJShw4d8lNV1jBv3jwNGjRIknT8+HFFRka69V8/h3n1F2TM7fDv8OKLL+o3v/mNx7fE5jUfpUuXVkhIiH788UedOHFCNWrU8Ngfcyrt3LlTpUuX1sMPP6wmTZrovvvu0+rVq139zO2tSU1N1aJFi9S1a1eNGTNGffr00fvvv68aNWrwO6CI+GIeb/bzX5KV6EBz/vx51yrD9UJCQtwueIW7NWvWaMeOHRoyZIikvOcxJCREV69elTGmQPOc3z5K8r/DwYMHtXTpUo0fP96j72Zzxpzm78yZM0pJSdELL7ygXbt2afbs2Ro6dKg2btwoibm9VVFRURo1apQ+/fRTvfbaa4qLi1OrVq0k8TugqPhiHm/nv3slOtDY7XZdvXrVo/3KlSsqXbq0Hyoq/o4cOaKhQ4fqgw8+cH2HSF7zeOXKFdntdtlstgLNc377KMn/DmPHjlVKSkqev1xuNmfMaf4CAgI0YcIERUdHS5KaNGmiP/zhD1qwYIEk5vZWPfbYY3r33Xe1fv16HTx4UMHBwWrSpImOHj3K74Ai4ot5vJ3/7pXoQFOpUiVduXJFFy9edGs/cuRInkvOt7tLly6pV69eSklJUcuWLV3tNWrU0Pfff+829vo5zKu/IGNK8r/D6tWrdfnyZT388MN59uc1H9d+VitXrsyc3kDlypVVv359t7a6devq1KlTkpjbW/Hdd99p5cqVWr9+vTp16qQ6deooNTVVXbt21RtvvMHvgCLii3m82c9/SVaiA43NZlObNm20adMmt/bPP/9c7du391NVxVNOTo4SEhL0wAMPaODAgW597du31+eff+7Wdv0cxsbG6sCBAzp//ryr3+FwKC0tTc2bNy/QPkqa9PR0HT16VLGxsa7XvHnz9NZbb6lly5Z5zsemTZvUqlUrBQQEqGrVqipbtqz27Nnj6s/NzdXmzZtdc3a7zek1rVq10n//+1+3tgMHDqhu3bqS8p4X5vbGHA6HqlWrpvDwcLf2xo0b69y5c/wOKCK+mMeb/fyXaP68xcoXPv74Y9OiRQuTkZFhjPnpOTSNGzd2PWsBPxk1apTp27evyc3N9ei7ePGiqVmzptuzE+rWrWu2bdvmGjNmzBjXsxNyc3PNqFGjzMiRI139//73v02dOnVcz07YvHmziYyMNBcuXPDyJys+rr9tOzc318TGxno8K2Lx4sWu8S+//LLp1q2bcTqdxpifnpXy4IMPuvqPHDliqlWr5vaslOrVq5vDhw/76iP5xbp160yjRo1cz4TZs2ePiYqKMnv37jXGMLe3Ijs727Ru3dq8/PLLrt+N3333nWnQoIHZvHkzvwNu0c9v2/bFPBbk57+kKvGBxpifnilx1113mZiYGPPrX//aHDp0yN8lFStnz541kkyDBg1M06ZNXa/Y2Fjzww8/GGOM2bFjh2nfvr1p0qSJiYmJMX/729/c9nHlyhUzbNgwEx0dbaKjo83gwYM9Hpi1cOFC07hxY9OkSRPTtm1b8/XXX/vsMxYHKSkpZvLkya7tw4cPm7i4OBMTE2MaNmxoZs2a5TY+NzfXTJo0yURHR5u77rrLPPzww+bUqVNuYz799FPTvHlz06RJE9OsWTOzdu1an3wWf3vzzTdNvXr1TIMGDUzz5s3NqlWr3PqZ28I7deqUGTp0qGncuLGJjY017du3N8uWLXP18zug8OrVq+cRgn0xjzf7+S+pbMaU8BvTAQBAiVfCT6gBAIDbAYEGAABYHoEGAABYHoEGAABYHoEGAABYHoEGAABYHoEGAABYHoEGAABYHoEGAABYHoEGAABY3v8HVP/v0UpDfZYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams['font.family'] = 'NanumGothic' # 한글 폰트 설정\n",
    "\n",
    "train_df['label'].value_counts(ascending=True).plot.barh()\n",
    "plt.title('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "56f95346-23b1-4573-9675-1f08a24b145a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at monologg/distilkobert were not used when initializing DistilBertForSequenceClassification: ['vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_projector.bias', 'vocab_transform.bias', 'vocab_projector.weight']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at monologg/distilkobert and are newly initialized: ['classifier.bias', 'pre_classifier.weight', 'pre_classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'DistilBertTokenizer'. \n",
      "The class this function is called from is 'KoBertTokenizer'.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "from tokenization_kobert import KoBertTokenizer\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained('monologg/distilkobert')\n",
    "tokenizer = KoBertTokenizer.from_pretrained('monologg/distilkobert')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "4e4d5693-f6bc-43b7-9ca4-30b64b4c7f72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "d724f57e-478d-4a67-97e5-e83c69234100",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract labels\n",
    "id2label = {}\n",
    "label2id = {}\n",
    "\n",
    "for i, label in enumerate(shuffled_data.label.unique()):\n",
    "    id2label[i] = label\n",
    "    label2id[label] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "bae601d4-275d-4ff8-aacc-1e4564bbe314",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, df, label2id):\n",
    "        self.data = df.values\n",
    "        self.label2id = label2id\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        result = self.data[idx, 0]\n",
    "        result = tokenizer(result, truncation=True, return_token_type_ids=False)\n",
    "        label = self.data[idx, -1]\n",
    "        label = self.label2id[label]\n",
    "        result['label'] = label\n",
    "        \n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "1ebde197-f6bf-48ab-8776-fb362f8112dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'input_ids': [2, 3010, 5561, 7850, 4003, 6383, 5782, 54, 3], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1], 'label': 0},\n",
       " {'input_ids': [2, 3093, 7682, 6553, 3650, 6285, 6812, 6183, 5761, 0, 3], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'label': 4})"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, SubsetRandomSampler\n",
    "import random\n",
    "\n",
    "# pandas 데이터를 train, validation, test로 나눈다 (약 8:1:1 비율로 생성)\n",
    "train_df, test_df = train_test_split(shuffled_data, test_size=0.1, random_state=42)\n",
    "train_df, validation_df = train_test_split(train_df, test_size=0.11, random_state=42)\n",
    "\n",
    "# Dataset 생성\n",
    "train_ds, validation_ds, test_ds = CustomDataset(train_df, label2id), CustomDataset(validation_df, label2id), CustomDataset(test_df, label2id)\n",
    "\n",
    "train_ds.__getitem__(0), validation_ds.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "61d3e1c2-ddda-4543-ba79-8b3ec5f24a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, padding='longest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "52f3afc8-66e8-413b-ae6b-eb52f34dbff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evalate\n",
    "import evaluate\n",
    "\n",
    "accuracy = evaluate.load('accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "ce281d9b-e60b-430c-bbc7-678ecfd25b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return accuracy.compute(predictions=predictions, labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "f39aedd6-a8dc-48b3-8db4-028b91a3bbad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at monologg/distilkobert were not used when initializing DistilBertForSequenceClassification: ['vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_projector.bias', 'vocab_transform.bias', 'vocab_projector.weight']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at monologg/distilkobert and are newly initialized: ['classifier.bias', 'pre_classifier.weight', 'pre_classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"monologg/distilkobert\", num_labels=len(id2label), id2label=id2label, label2id=label2id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "84f35c09-fe67-4400-b39e-fcf09191459b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DistilBertConfig {\n",
       "  \"_name_or_path\": \"monologg/distilkobert\",\n",
       "  \"activation\": \"gelu\",\n",
       "  \"architectures\": [\n",
       "    \"DistilBertForMaskedLM\"\n",
       "  ],\n",
       "  \"attention_dropout\": 0.1,\n",
       "  \"dim\": 768,\n",
       "  \"dropout\": 0.1,\n",
       "  \"hidden_dim\": 3072,\n",
       "  \"id2label\": {\n",
       "    \"0\": \"\\uc911\\ub9bd\",\n",
       "    \"1\": \"\\uad34\\ub85c\\uc6c0\",\n",
       "    \"2\": \"\\uc2eb\\uc74c\",\n",
       "    \"3\": \"\\ud589\\ubcf5\",\n",
       "    \"4\": \"\\uc2ac\\ud514\",\n",
       "    \"5\": \"\\uc124\\ub818\",\n",
       "    \"6\": \"\\uac10\\ub3d9\",\n",
       "    \"7\": \"\\uae30\\uc068\",\n",
       "    \"8\": \"\\ub2f9\\ud669\",\n",
       "    \"9\": \"\\ud6c4\\ud68c\"\n",
       "  },\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"label2id\": {\n",
       "    \"\\uac10\\ub3d9\": 6,\n",
       "    \"\\uad34\\ub85c\\uc6c0\": 1,\n",
       "    \"\\uae30\\uc068\": 7,\n",
       "    \"\\ub2f9\\ud669\": 8,\n",
       "    \"\\uc124\\ub818\": 5,\n",
       "    \"\\uc2ac\\ud514\": 4,\n",
       "    \"\\uc2eb\\uc74c\": 2,\n",
       "    \"\\uc911\\ub9bd\": 0,\n",
       "    \"\\ud589\\ubcf5\": 3,\n",
       "    \"\\ud6c4\\ud68c\": 9\n",
       "  },\n",
       "  \"max_position_embeddings\": 512,\n",
       "  \"model_type\": \"distilbert\",\n",
       "  \"n_heads\": 12,\n",
       "  \"n_layers\": 3,\n",
       "  \"pad_token_id\": 1,\n",
       "  \"qa_dropout\": 0.1,\n",
       "  \"seq_classif_dropout\": 0.2,\n",
       "  \"sinusoidal_pos_embds\": false,\n",
       "  \"tie_weights_\": true,\n",
       "  \"transformers_version\": \"4.28.1\",\n",
       "  \"vocab_size\": 8002\n",
       "}"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "bd71226f-3191-4fb9-b4f0-d65817f8d909",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elicer/.local/lib/python3.10/site-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='64200' max='64200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [64200/64200 2:03:34, Epoch 30/30]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.767600</td>\n",
       "      <td>1.085683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.889000</td>\n",
       "      <td>1.044170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.718300</td>\n",
       "      <td>1.135978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.714900</td>\n",
       "      <td>1.104194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.650200</td>\n",
       "      <td>1.115530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.658600</td>\n",
       "      <td>1.067738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.517600</td>\n",
       "      <td>1.131999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.547900</td>\n",
       "      <td>1.125430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.436100</td>\n",
       "      <td>1.200435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.433000</td>\n",
       "      <td>1.199078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>0.384300</td>\n",
       "      <td>1.234987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.349800</td>\n",
       "      <td>1.330866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>0.334900</td>\n",
       "      <td>1.372528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>0.288300</td>\n",
       "      <td>1.408144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>0.296100</td>\n",
       "      <td>1.417458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>0.255700</td>\n",
       "      <td>1.490802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17000</td>\n",
       "      <td>0.272100</td>\n",
       "      <td>1.515563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18000</td>\n",
       "      <td>0.218100</td>\n",
       "      <td>1.645429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19000</td>\n",
       "      <td>0.214800</td>\n",
       "      <td>1.744110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>0.187300</td>\n",
       "      <td>1.824533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21000</td>\n",
       "      <td>0.169800</td>\n",
       "      <td>1.955264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22000</td>\n",
       "      <td>0.142100</td>\n",
       "      <td>2.083660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23000</td>\n",
       "      <td>0.162100</td>\n",
       "      <td>1.993420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24000</td>\n",
       "      <td>0.138300</td>\n",
       "      <td>2.125405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25000</td>\n",
       "      <td>0.143700</td>\n",
       "      <td>2.251336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26000</td>\n",
       "      <td>0.139400</td>\n",
       "      <td>2.276160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27000</td>\n",
       "      <td>0.130800</td>\n",
       "      <td>2.428460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28000</td>\n",
       "      <td>0.137100</td>\n",
       "      <td>2.420898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29000</td>\n",
       "      <td>0.118200</td>\n",
       "      <td>2.467905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30000</td>\n",
       "      <td>0.108700</td>\n",
       "      <td>2.657125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31000</td>\n",
       "      <td>0.114700</td>\n",
       "      <td>2.625486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32000</td>\n",
       "      <td>0.109600</td>\n",
       "      <td>2.660517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33000</td>\n",
       "      <td>0.095400</td>\n",
       "      <td>2.905035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34000</td>\n",
       "      <td>0.097500</td>\n",
       "      <td>2.866918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35000</td>\n",
       "      <td>0.088900</td>\n",
       "      <td>3.024962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36000</td>\n",
       "      <td>0.095000</td>\n",
       "      <td>3.052338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37000</td>\n",
       "      <td>0.080200</td>\n",
       "      <td>3.105935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38000</td>\n",
       "      <td>0.080300</td>\n",
       "      <td>3.165950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39000</td>\n",
       "      <td>0.070700</td>\n",
       "      <td>3.226913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40000</td>\n",
       "      <td>0.069700</td>\n",
       "      <td>3.320735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41000</td>\n",
       "      <td>0.072000</td>\n",
       "      <td>3.318040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42000</td>\n",
       "      <td>0.060100</td>\n",
       "      <td>3.451333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43000</td>\n",
       "      <td>0.064600</td>\n",
       "      <td>3.476273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44000</td>\n",
       "      <td>0.065500</td>\n",
       "      <td>3.501430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45000</td>\n",
       "      <td>0.050500</td>\n",
       "      <td>3.515765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46000</td>\n",
       "      <td>0.059800</td>\n",
       "      <td>3.540491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47000</td>\n",
       "      <td>0.073000</td>\n",
       "      <td>3.518476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48000</td>\n",
       "      <td>0.044200</td>\n",
       "      <td>3.561462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49000</td>\n",
       "      <td>0.055100</td>\n",
       "      <td>3.633234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50000</td>\n",
       "      <td>0.050300</td>\n",
       "      <td>3.674646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51000</td>\n",
       "      <td>0.055300</td>\n",
       "      <td>3.691791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52000</td>\n",
       "      <td>0.035800</td>\n",
       "      <td>3.733799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53000</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>3.726441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54000</td>\n",
       "      <td>0.029800</td>\n",
       "      <td>3.787002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55000</td>\n",
       "      <td>0.045500</td>\n",
       "      <td>3.805608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56000</td>\n",
       "      <td>0.031700</td>\n",
       "      <td>3.818803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57000</td>\n",
       "      <td>0.042600</td>\n",
       "      <td>3.862343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58000</td>\n",
       "      <td>0.036500</td>\n",
       "      <td>3.874191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59000</td>\n",
       "      <td>0.042100</td>\n",
       "      <td>3.883481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60000</td>\n",
       "      <td>0.037800</td>\n",
       "      <td>3.918056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61000</td>\n",
       "      <td>0.038000</td>\n",
       "      <td>3.920176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62000</td>\n",
       "      <td>0.036200</td>\n",
       "      <td>3.908234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>63000</td>\n",
       "      <td>0.024200</td>\n",
       "      <td>3.925783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64000</td>\n",
       "      <td>0.032100</td>\n",
       "      <td>3.924797</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=64200, training_loss=0.20025618886650537, metrics={'train_runtime': 7415.0101, 'train_samples_per_second': 138.469, 'train_steps_per_second': 8.658, 'total_flos': 1.1583758150471976e+16, 'train_loss': 0.20025618886650537, 'epoch': 30.0})"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"my_awesome_model\",\n",
    "    learning_rate=4e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=30,\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    save_strategy=\"steps\",\n",
    "    eval_steps=1000, \n",
    "    save_steps=1000,\n",
    "    save_total_limit=10,\n",
    "    load_best_model_at_end=True\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=validation_ds,\n",
    "#    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    # compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4596daa-ea61-471e-af05-92f055612d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "\n",
    "transformers.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "273088ab-1c62-4ee5-b702-bb7bea13ec37",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer(\"동해물과 백두산이 마르고 닳도록 하느님이 보우하사 우리나라 만세 무궁화 삼천리 화려강산 대한사람 대한으로 길이 보전하세\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f43b8f6-48fb-4f9b-b28d-6982577fddf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파이프라인 가져올 때 model은 사용중인 model을 주면 댐\n",
    "# pipeline(‘sentiment-analysis’, model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2485604-9dcf-47e4-8d8a-0bcdf4b6de8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# yhat = trainer.predict(test_ds)\n",
    "# print(yhat)\n",
    "\n",
    "# predictions = yhat[‘predictions’]\n",
    "# labels = yhat[‘labels’]\n",
    "# predictions = np.argmax(predictions, axis=1)\n",
    "# accuracy.compute(predictions=predictions, references=labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
